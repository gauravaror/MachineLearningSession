{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPAM/HAM detection\n",
    "\n",
    "We would be using bouquet of algorithms to train Spam detector and compare there accuracy:\n",
    "\n",
    "## Algorithm used.\n",
    "\n",
    "* Naive Bayes Algorithms - 2\n",
    "* SVM based Classification Algorithm.\n",
    "\n",
    "## Steps of our SPAM/HAM algorithm\n",
    "\n",
    "1.  Import relevant packages\n",
    "2.  Import the test and training data\n",
    "3.  Vectorize or featurize our test and training data.\n",
    "4.  Running classification algorithms on our vectorized data\n",
    "5.  Comparing the results using plots\n",
    "\n",
    "Let's start by importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import sys\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets.base import load_files\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categories\n",
    "\n",
    "This is two class classification problem:\n",
    "\n",
    "1. SPAM\n",
    "2. HAM\n",
    "\n",
    "Let's define the categories and load our training dataset:\n",
    "\n",
    "We have divided all our emails in two sets:\n",
    "1. Train :  Files we would be using to train our Classification algorithm\n",
    "2. Test  : Files we would be using to test accuracy of our models.\n",
    "\n",
    "## Collection Statistics\n",
    "\n",
    "```\n",
    " |          | Number of Spam | Number of HAM |\n",
    " | Training | 4496           | 12045         |\n",
    " | Test     | 4500           | 1500          |\n",
    "```\n",
    "## Directory structure of our test/train collection\n",
    "\n",
    "Our collection is organized as follows on directory level:\n",
    "\n",
    "~/Documents/IRLAB/MachineLearningSession/assets » ls spamham/                                       gaurav@Gaurav\n",
    "test   train\n",
    "\n",
    "~/Documents/IRLAB/MachineLearningSession/assets » ls spamham/test                                   gaurav@Gaurav\n",
    "ham  spam\n",
    "\n",
    "~/Documents/IRLAB/MachineLearningSession/assets » ls spamham/test/ham |wc -l                        gaurav@Gaurav\n",
    "    1500\n",
    "\n",
    "~/Documents/IRLAB/MachineLearningSession/assets » ls spamham/test/spam |wc -l                       gaurav@Gaurav\n",
    "    4500\n",
    "\n",
    "## Sample of a spam document\n",
    "```\n",
    "Subject: good day dear sir ,\n",
    "good day dear customer , ! : )\n",
    "very cheap pharmacy for lowest price !\n",
    "meridia 75 $\n",
    "prozac 70 $\n",
    "viagra 64 $\n",
    "xenical 70 $\n",
    "celebrex 72 $\n",
    "glucophage 60 $\n",
    "prozac 70 $\n",
    "glucophage 60 $\n",
    "prozac 70 $\n",
    "prozac 70 $\n",
    "visit our shop right now and get 90 % dicsount\n",
    "just wanna say you , that i am really wants to help up your health with generic - drugs shop = )\n",
    "thank you for cooperation .\n",
    "spamham/test/spam/3979.2005-01-21.GP.spam.txt (END)\n",
    "```\n",
    "## Sample of HAM Document\n",
    "```\n",
    "Subject: caiso notice - market certifications for november , 2000 through\n",
    "may , 2001\n",
    "iso market participants\n",
    "sc settlement contacts\n",
    "attached are the summaries of market certifications for november and\n",
    "december , 2000 and for january - may , 2001 . the iso will mail individual\n",
    "certifications to creditors later this week .\n",
    ">\n",
    "client relations communications\n",
    "crcommunications @ caiso . com\n",
    "spamham/test/ham/2571.2001-08-29.williams.ham.txt (END)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    'spam',\n",
    "    'ham',\n",
    "]\n",
    "    \n",
    "    \n",
    "data_train = load_files('assets/spamham/train/')\n",
    "data_test = load_files('assets/spamham/test/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gauge size of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16541 documents - 28.911MB (training set)\n",
      "6000 documents - 6.839MB (test set)\n",
      "2 categories\n",
      "['ham', 'spam']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def size_mb(docs):\n",
    "    return sum(len(s) for s in docs) / 1e6\n",
    "\n",
    "data_train_size_mb = size_mb(data_train.data)\n",
    "data_test_size_mb = size_mb(data_test.data)\n",
    "\n",
    "print(\"%d documents - %0.3fMB (training set)\" % (\n",
    "    len(data_train.data), data_train_size_mb))\n",
    "print(\"%d documents - %0.3fMB (test set)\" % (\n",
    "    len(data_test.data), data_test_size_mb))\n",
    "print(\"%d categories\" % len(categories))\n",
    "target_names = data_train.target_names\n",
    "print(target_names)\n",
    "\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Convert our training data from text to trainable set\n",
    "\n",
    "We would like to extract features from our training data.\n",
    "\n",
    "Converting text data into features, easiest is to extract terms in the documents as use them as features.\n",
    "\n",
    "We would be using TDIDF vectorization.\n",
    "\n",
    "Simplest feature can be if term is present or not. i.e\n",
    "If we have two documents\n",
    "\n",
    "# Term presence as feature\n",
    "## document1 = \"This is a text document for the analysis in document\"\n",
    "## document2 = \"text analysis is  relatively old field\"\n",
    "\n",
    "##### Terms:       This, is, a, text, document, for, the , analysis, in, relatively, old, field\n",
    "##### document1:       1, 1, 1,    1,         1,  1,   1,         1,  1,        0,    0,     0\n",
    "##### document2:       0, 1, 0,    1,         0,  0,   0,         1,  0,        1,    1,     1\n",
    "\n",
    "\n",
    "# Term frequence as a feature:\n",
    "##### Terms:         This, is, a, text, document, for, the , analysis, in, relatively, old, field\n",
    "##### document1:       1, 1, 1,    1,         2,  1,   1,         1,  1,        0,    0,     0\n",
    "##### document2:       0, 1, 0,    1,         0,  0,   0,         1,  0,        1,    1,     1\n",
    "\n",
    "\n",
    "# Tf-IDF frequence as a feature:\n",
    "##### Terms:       This, is,   a,    text,  document, for,    the , analysis, in,    relatively, old, field\n",
    "##### document1:   1/10, 1/10, 1/10, 1/10,  2/10,     1/10,   1/10, 1/10,     1/10,  0,          0,     0\n",
    "##### document2:   0,    1/5,  0,    1/5,   0,        0,      0,    1/5,      0,     1/5,        1/5,     1/5\n",
    "\n",
    "We convert out whole collection into such structure and ideally above structure is a matrix of [Number of documents X unique terms in collection]\n",
    "\n",
    "scikitlearn store them as a sparse representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 5.507809s at 5.249MB/s\n",
      "n_samples: 16541, n_features: 97127\n",
      "\n",
      "Extracting features from the test data using the same vectorizer\n",
      "done in 1.344249s at 5.088MB/s\n",
      "n_samples: 6000, n_features: 97127\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# split a training set and a test set\n",
    "t0 = time()\n",
    "\n",
    "y_train, y_test = data_train.target, data_test.target\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                                 stop_words='english', decode_error='ignore')\n",
    "X_train = vectorizer.fit_transform(data_train.data)\n",
    "\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_train_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
    "print()\n",
    "\n",
    "print(\"Extracting features from the test data using the same vectorizer\")\n",
    "t0 = time()\n",
    "X_test = vectorizer.transform(data_test.data)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_test_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore how our training data looks\n",
    "\n",
    "Sparse representation of our documents below.\n",
    "sparse representation is very quick in calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (1, 51279)\t0.29410720636628096\n",
      "  (1, 72640)\t0.2900951642519912\n",
      "  (1, 48626)\t0.3186735637798252\n",
      "  (1, 77850)\t0.233534969062361\n",
      "  (1, 14149)\t0.09663735805214535\n",
      "  (1, 65773)\t0.2360383927871424\n",
      "  (1, 73768)\t0.18657033933021666\n",
      "  (1, 67273)\t0.13985095325422417\n",
      "  (1, 43364)\t0.17539500725662702\n",
      "  (1, 39399)\t0.1174093466098221\n",
      "  (1, 56731)\t0.1396218805155503\n",
      "  (1, 3169)\t0.10233712215771187\n",
      "  (1, 2126)\t0.08488190526551385\n",
      "  (1, 70251)\t0.1844626782042132\n",
      "  (1, 31109)\t0.16792483136678188\n",
      "  (1, 43404)\t0.1464218284925751\n",
      "  (1, 25691)\t0.17324560866133024\n",
      "  (1, 72220)\t0.10218464657695014\n",
      "  (1, 24871)\t0.21091356893789512\n",
      "  (1, 44328)\t0.185150842778414\n",
      "  (1, 25287)\t0.10699712107897968\n",
      "  (1, 77524)\t0.2865062702856676\n",
      "  (1, 30782)\t0.29410720636628096\n",
      "  (1, 5792)\t0.29865568457287317\n",
      "  (2, 90259)\t0.2986487547113796\n",
      "  :\t:\n",
      "  (16540, 77850)\t0.1910773748846033\n",
      "  (16540, 91860)\t0.130505324119128\n",
      "  (16540, 68664)\t0.1144494380626178\n",
      "  (16540, 87754)\t0.16850160059539995\n",
      "  (16540, 54003)\t0.12384498627476627\n",
      "  (16540, 52201)\t0.11269095181618966\n",
      "  (16540, 57915)\t0.2628676926002945\n",
      "  (16540, 30430)\t0.18035538524361\n",
      "  (16540, 73910)\t0.1743730395310732\n",
      "  (16540, 54384)\t0.1260684668501132\n",
      "  (16540, 86206)\t0.108087541308526\n",
      "  (16540, 0)\t0.1424311819684524\n",
      "  (16540, 2512)\t0.17787982249862183\n",
      "  (16540, 88579)\t0.17783433974753035\n",
      "  (16540, 14577)\t0.15961920032351481\n",
      "  (16540, 76291)\t0.21898288959662893\n",
      "  (16540, 79644)\t0.19223505549172953\n",
      "  (16540, 5371)\t0.2594756273982295\n",
      "  (16540, 40276)\t0.22271469096688418\n",
      "  (16540, 24770)\t0.19030133138822908\n",
      "  (16540, 44074)\t0.20087553402898822\n",
      "  (16540, 87436)\t0.2632099870266299\n",
      "  (16540, 32680)\t0.2804391056253005\n",
      "  (16540, 44482)\t0.3093090112471874\n",
      "  (16540, 8208)\t0.293748497556963\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define benchmark function\n",
    "\n",
    "We can pass in any algorithm from scikit learn and we would get the result on our data set for those algorithms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(s):\n",
    "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
    "    return s if len(s) <= 80 else s[:77] + \"...\"\n",
    "\n",
    "# #############################################################################\n",
    "# Benchmark classifiers\n",
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "        print()\n",
    "\n",
    "    print(\"classification report:\")\n",
    "    print(metrics.classification_report(y_test, pred,\n",
    "                                        target_names=target_names))\n",
    "    print(\"confusion matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score, train_time, test_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run our classifier on Naive Bayes and Linear SVC\n",
    "\n",
    "We will be running and comparing our score on precision, recall, f1 scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "train time: 0.036s\n",
      "test time:  0.008s\n",
      "accuracy:   0.950\n",
      "dimensionality: 97127\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.87      0.94      0.90      1500\n",
      "       spam       0.98      0.95      0.97      4500\n",
      "\n",
      "avg / total       0.95      0.95      0.95      6000\n",
      "\n",
      "confusion matrix:\n",
      "[[1407   93]\n",
      " [ 206 4294]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "train time: 0.044s\n",
      "test time:  0.020s\n",
      "accuracy:   0.972\n",
      "dimensionality: 97127\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.96      0.92      0.94      1500\n",
      "       spam       0.97      0.99      0.98      4500\n",
      "\n",
      "avg / total       0.97      0.97      0.97      6000\n",
      "\n",
      "confusion matrix:\n",
      "[[1385  115]\n",
      " [  55 4445]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
      "     verbose=0)\n",
      "train time: 0.157s\n",
      "test time:  0.002s\n",
      "accuracy:   0.975\n",
      "dimensionality: 97127\n",
      "density: 0.726873\n",
      "\n",
      "classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.98      0.92      0.95      1500\n",
      "       spam       0.97      0.99      0.98      4500\n",
      "\n",
      "avg / total       0.98      0.98      0.98      6000\n",
      "\n",
      "confusion matrix:\n",
      "[[1385  115]\n",
      " [  33 4467]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "results.append(benchmark(MultinomialNB(alpha=.01)))\n",
    "results.append(benchmark(BernoulliNB(alpha=.01)))\n",
    "results.append(benchmark(LinearSVC(penalty=\"l2\", dual=True, tol=1e-3)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the train time, test time and score of all the three algorithm for spam detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109b63da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make some plots\n",
    "\n",
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "clf_names, score, training_time, test_time = results\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "test_time = np.array(test_time) / np.max(test_time)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Score\")\n",
    "plt.barh(indices, score, .2, label=\"score\", color='navy')\n",
    "plt.barh(indices + .3, training_time, .2, label=\"training time\",\n",
    "         color='c')\n",
    "plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n",
    "plt.yticks(())\n",
    "plt.legend(loc='best')\n",
    "plt.subplots_adjust(left=.25)\n",
    "plt.subplots_adjust(top=.95)\n",
    "plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "for i, c in zip(indices, clf_names):\n",
    "    plt.text(-.3, i, c)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
